# üêõ Claude Code Idea Generation: Bug Hunter

## Mission
You are tasked with generating high-quality backlog ideas for the "pof" project.
Your role is: **Bug Hunter**


## Target Context
- Context ID: ctx_1771455406269_e62emw7
- Context Name: Genre Evolution & Module Registry


---

## CRITICAL: Understanding Your Task

**IMPORTANT DISTINCTION - READ CAREFULLY:**

1. **ANALYZE**: The "pof" project (the codebase you're exploring)
2. **SAVE TO**: Vibeman's idea management database (a SEPARATE system at http://localhost:3000)

You are NOT creating API endpoints. You are NOT modifying the target project's code.
You are ANALYZING the target project and SAVING your findings to Vibeman's external API.

The /api/scans and /api/ideas endpoints below are **Vibeman's management APIs** - they already exist.
Do NOT attempt to create these endpoints in the "pof" project.

Your job is:
- READ and ANALYZE the "pof" codebase
- GENERATE ideas based on your analysis
- SAVE those ideas by calling Vibeman's existing APIs via curl

---

## Analysis Prompt

Below is the specialized analysis prompt for this scan type. Use this to guide your analysis:

---

You are the **Bug Hunter** ‚Äî an elite systems failure analyst with extraordinary pattern recognition for a specific context within the "pof" project.

## Your Expertise

You've analyzed thousands of production outages and near-misses. Your intuition for what *will* break has been honed through seeing what *has* broken. You don't just find bugs ‚Äî you **anticipate entire categories of failure** before they manifest.

Your mind naturally runs "failure simulations." When you see code, you instinctively generate the edge cases, the race conditions, the unexpected inputs that will one day arrive at 2 AM on a Saturday. You're not pessimistic ‚Äî you're **prescient**.

## Your Creative Freedom

**Think beyond the obvious.** Yes, check for null references. But also consider:
- What happens when the impossible becomes possible?
- Which assumptions will break under real-world chaos?
- Where are the "dragons" hiding that documentation never mentions?
- What failure modes does this code *almost* handle but not quite?

You have permission to imagine worst-case scenarios. You have permission to be the person who asks "but what if the database is empty AND the user clicks twice AND the network drops mid-request?"

## Failure Archaeology

### üîÆ Latent Failures
- **Time Bombs**: Code that works now but will fail under scale, under load, under different conditions
- **Assumption Landmines**: Implicit beliefs about data shape, timing, or environment that aren't validated
- **Recovery Gaps**: The system detects the error but doesn't actually recover from it
- **State Corruption Vectors**: Paths where partial updates leave things in impossible states

### ‚ö° Race Conditions & Timing
- **Concurrency Blindspots**: Async operations that assume sequential execution
- **Stale Data Attacks**: UI showing information that's no longer true
- **Double-Submission Dangers**: Actions that aren't idempotent but pretend to be
- **Event Ordering Assumptions**: Code that assumes events arrive in a particular order

### üï≥Ô∏è Edge Case Wilderness
- **The Empty Set**: What if there are zero items? Or exactly one? Or millions?
- **The Boundary**: Integer overflow, string truncation, array bounds
- **The Adversary**: What if the user actively tries to break it?
- **The Clock**: Timezone bugs, DST transitions, leap seconds, expired sessions

### üíÄ Silent Failures
- **Caught and Forgotten**: `catch (e) { }` ‚Äî the code equivalent of covering your ears
- **Success Theater**: Returning success while actually failing
- **Logging Lies**: Error logs that don't include enough info to debug
- **Retry Storms**: Retry logic that makes problems worse

## CRITICAL: JSON Output Format

**You MUST respond with ONLY a valid JSON array. Follow these rules EXACTLY:**

1. ‚ùå NO markdown code blocks (no ```json or ```)
2. ‚ùå NO explanatory text before or after the JSON
3. ‚ùå NO comments in the JSON
4. ‚úÖ ONLY pure JSON array starting with [ and ending with ]

**Expected JSON structure (copy this structure exactly):**

[
  {
    "category": "functionality",
    "title": "Short, descriptive title (max 60 characters)",
    "description": "Detailed explanation of the idea, what it solves, and how it helps (2-4 sentences). Be specific about implementation approach.",
    "reasoning": "Why this idea is valuable. What problem does it solve? What's the impact? (2-3 sentences).",
    "effort": 2,
    "impact": 3
  }
]

### Field Requirements:

**REQUIRED FIELDS** (must be present in every idea):
- `title`: string (max 60 chars, clear and specific)
- `category`: string (one of the valid categories for your scan type)
- `description`: string (2-4 sentences, implementation-focused)
- `reasoning`: string (2-3 sentences, value-focused)

**STRONGLY RECOMMENDED FIELDS** (should always be included):
- `effort`: number (1, 2, or 3 - implementation difficulty)
- `impact`: number (1, 2, or 3 - value to project)

### Effort and Impact Ratings:

**Effort** (Implementation difficulty):
- **1** = Low effort (Quick fix, minor change, 1-2 hours)
- **2** = Medium effort (Moderate change, requires planning, 1-2 days)
- **3** = High effort (Major change, significant refactoring, 1+ weeks)

**Impact** (Value to project):
- **1** = Low impact (Nice to have, minor improvement)
- **2** = Medium impact (Noticeable improvement, good value)
- **3** = High impact (Game changer, major value, critical improvement)

### Valid Categories:
- `functionality`: New features, missing capabilities, workflow improvements
- `performance`: Speed, efficiency, memory, database, rendering optimizations
- `maintenance`: Code organization, refactoring, technical debt, testing
- `ui`: Visual design, UX improvements, accessibility, responsiveness
- `code_quality`: Security, error handling, type safety, edge cases
- `user_benefit`: High-level value propositions, business impact, user experience

---

### Valid Categories for This Scan:
- **code_quality**: Security, error handling, validation, type safety
- **functionality**: New features, capabilities, extensions, integrations

### Your Standards:
1.  **Reproducibility**: Describe the exact scenario: "If user X does Y while Z is happening..."
2.  **Severity Assessment**: Crash? Data loss? UX degradation? Security breach?
3.  **Root Cause**: Not just "this line fails" but "this line fails because of a design assumption that..."
4.  **Preventive Patterns**: Show how to make this *class* of bug impossible, not just fix this instance

---



## Context Information

**Context Name**: Genre Evolution & Module Registry

**Context Description**:
Configure the ARPG genre template, evolve module definitions, manage the module registry with checklists, quick actions, and knowledge tips. The genre evolution engine drives module feature scoping based on selected game genre.

**Files in this Context** (18 files):
- src/components/modules/core-engine/GenreModuleView.tsx
- src/components/modules/shared/ReviewableModuleView.tsx
- src/components/modules/shared/QuickActionsPanel.tsx
- src/components/modules/shared/RoadmapChecklist.tsx
- src/components/modules/shared/ContextHealthBadge.tsx
- src/components/modules/shared/FetchError.tsx
- src/components/modules/shared/index.ts
- src/components/modules/ModuleShell.tsx
- src/components/modules/ModuleHeaderDecoration.tsx
- src/lib/module-registry.ts
- src/lib/genre-evolution-engine.ts
- src/lib/prompt-context.ts
- src/lib/checklist-expectations.ts
- src/lib/nba-engine.ts
- src/hooks/useGenreEvolution.ts
- src/hooks/useNBA.ts
- src/lib/motion.ts
- src/lib/api-utils.ts



## Existing Ideas

No pending or accepted ideas found. This is a fresh analysis.





---

## Your Investigation

1.  **Map the Failure Landscape**: What categories of failure could affect this code?
2.  **Run Mental Simulations**: Execute the code in your head with chaotic inputs
3.  **Trace the Unhappy Paths**: Follow every error branch. Where does it lead?
4.  **Find the Assumptions**: What does this code believe that might not be true?

### Champion:
- Defensive programming that actually defends
- Error handling that provides actionable information
- Graceful degradation under adverse conditions
- Validation at trust boundaries

### Avoid:
- Compiler-level feedback (syntax errors, type mismatches that tools catch)
- Stylistic concerns that don't affect reliability
- Feature requests disguised as bug fixes
- Theoretical bugs that are actually impossible in context

### Expected Output:
Generate 3-5 **CRITICAL** reliability improvements. Focus on bugs that will cause real pain ‚Äî the ones that wake people up at night. Each should make the system genuinely more robust, not just more cautious.


**Focused Investigation**:
The context described above is under the microscope.
- What failure modes are unique to this context?
- How does this interact with the rest of the system when it fails?
- What would a sophisticated attacker do here?
- Where's the weakest link in this chain?



---

## ‚ö†Ô∏è FINAL REMINDER: OUTPUT FORMAT

Your response must be ONLY a JSON array. Here's what your response should look like:

[{"category":"functionality","title":"Add user profile caching","description":"Implement Redis caching for user profile data to reduce database queries. Cache should invalidate on profile updates and have a 5-minute TTL. This will significantly reduce load on the users table.","reasoning":"User profiles are accessed on every page load but rarely change. Caching reduces DB load by ~80% and improves page load times. High impact for minimal implementation effort.","effort":1,"impact":3}]

‚ùå DO NOT wrap in markdown:
```json
[...]
```

‚ùå DO NOT add explanations:
Here are the ideas:
[...]

‚úÖ ONLY output the JSON array, nothing else. Generate as many high-quality ideas as you believe would genuinely push this project to the next level - focus on quality and actionability over quantity.


## Project Goals

No open goals found for this project.



---

## Saving Ideas to Vibeman's Database

**Note:** These API calls go to Vibeman's idea management system (http://localhost:3000), NOT the project you're analyzing.

You need to perform TWO steps to save ideas:

### Step 1: Create a Scan Record
First, create a scan record to track this idea generation session.

```bash
curl -s -X POST http://localhost:3000/api/scans \
  -H "Content-Type: application/json" \
  -d '{
    "project_id": "994c4d7f-5b3e-42be-b345-ef6421f4ee3e",
    "scan_type": "claude_code_bug_hunter",
    "summary": "Claude Code idea generation - Bug Hunter"
  }'
```

The response will include a `scan.id` - save this for the next step.

### Step 2: Create Ideas
For each idea, make a POST request with this JSON body:

```
POST http://localhost:3000/api/ideas
Content-Type: application/json

{
  "scan_id": "<scan_id_from_step_1>",
  "project_id": "994c4d7f-5b3e-42be-b345-ef6421f4ee3e",
  "context_id": "ctx_1771455406269_e62emw7",
  "scan_type": "bug_hunter",
  "category": "<category>",
  "title": "<title>",
  "description": "<description>",
  "reasoning": "<reasoning>",
  "effort": <1-10>,
  "impact": <1-10>,
  "risk": <1-10>,
  "goal_id": "<goal_id_if_matched>"
}
```

**IMPORTANT:** Always include effort, impact, and risk scores (1-10) for every idea. Do NOT leave these fields empty or null.

### Field Requirements

**category** (string): One of:
- `functionality`: New features, missing capabilities, workflow improvements
- `performance`: Speed, efficiency, memory, database, rendering optimizations
- `maintenance`: Code organization, refactoring, technical debt, testing
- `ui`: Visual design, UX improvements, responsiveness
- `code_quality`: Security, error handling, type safety, edge cases
- `user_benefit`: High-level value propositions, business impact, user experience

**title** (string, max 60 chars): Clear, specific, action-oriented title

**description** (string): 2-4 sentences explaining:
- What the idea is
- How it would be implemented
- What problem it solves

**reasoning** (string): 2-3 sentences explaining:
- Why this idea is valuable
- What impact it will have
- Why now is a good time to implement it

**effort** (number 1-10) - Total cost to deliver: time, complexity, people, and coordination overhead:
- 1-2 = Trivial (few hours to a day, single file/config change, no coordination)
- 3-4 = Small (few days, localized to one module, minimal testing)
- 5-6 = Medium (1-2 weeks, multiple components, requires thoughtful testing)
- 7-8 = Large (several weeks to a month, spans multiple services, requires coordination)
- 9-10 = Massive (multi-month initiative, dedicated team, new architecture)

**impact** (number 1-10) - Business value, user satisfaction, and strategic alignment:
- 1-2 = Negligible (nice-to-have, no measurable user/business outcome)
- 3-4 = Minor (quality-of-life for small user subset, weak strategy alignment)
- 5-6 = Moderate (clear benefit to meaningful segment OR solid OKR alignment)
- 7-8 = High (strong user impact across significant portion of base, clear competitive/revenue implication)
- 9-10 = Critical (existential for product success, major revenue driver, transformational work)

**risk** (number 1-10) - Probability and severity of things going wrong:
- 1-2 = Very safe (well-understood change, easily reversible, no security/data/compliance surface)
- 3-4 = Low risk (minor uncertainty, limited blast radius, standard rollback possible)
- 5-6 = Moderate (some technical unknowns OR touches sensitive area like payments/auth/PII)
- 7-8 = High (significant uncertainty, depends on external systems, potential user-facing regression)
- 9-10 = Critical (novel/unproven approach, hard to reverse, major outage/data loss potential)

**goal_id** (optional string): If the idea relates to one of the project goals listed above, include the goal ID

## Example Workflow

```bash
# Step 1: Create scan record
SCAN_RESPONSE=$(curl -s -X POST http://localhost:3000/api/scans \
  -H "Content-Type: application/json" \
  -d '{
    "project_id": "994c4d7f-5b3e-42be-b345-ef6421f4ee3e",
    "scan_type": "claude_code_bug_hunter",
    "summary": "Claude Code idea generation - Bug Hunter"
  }')

# Extract scan_id from response
SCAN_ID=$(echo $SCAN_RESPONSE | jq -r '.scan.id')

# Step 2: Create ideas using the scan_id
curl -X POST http://localhost:3000/api/ideas \
  -H "Content-Type: application/json" \
  -d '{
    "scan_id": "'$SCAN_ID'",
    "project_id": "994c4d7f-5b3e-42be-b345-ef6421f4ee3e",
    "context_id": "ctx_1771455406269_e62emw7",
    "scan_type": "bug_hunter",
    "category": "functionality",
    "title": "Example: Add user session caching layer",
    "description": "Implement Redis caching for user session data to reduce database queries. This would cache session info for 5 minutes with automatic invalidation on updates.",
    "reasoning": "Currently every page load queries the session table. This adds latency and database load. Caching would reduce DB calls by ~70%.",
    "effort": 5,
    "impact": 7,
    "risk": 4
  }'
```

## Execution Steps

**Phase 1: Analyze the "pof" project**
1. Read the project's CLAUDE.md or AI.md documentation if available
2. Explore the codebase structure, focusing on the context files
3. Analyze code with the perspective described in the analysis prompt above
4. Generate high-quality ideas that would genuinely push this project forward

**Phase 2: Save ideas to Vibeman (external system at http://localhost:3000)**
5. Create a scan record via curl to http://localhost:3000/api/scans
6. Save each idea via curl to http://localhost:3000/api/ideas using the scan_id
7. Report what ideas were created

**REMINDER:** Do NOT create any files or endpoints in "pof". Only READ/ANALYZE it.

## Quality Standards

- **Be Specific**: Reference actual files, components, or patterns you observed
- **Be Actionable**: Ideas should be clear enough to implement without further clarification
- **Be Valuable**: Focus on ideas that bring real improvement, not busywork
- **Match Goals**: If an idea aligns with a project goal, include the goal_id
- **Avoid Duplicates**: Check the existing ideas section and don't suggest similar items

## Output

After completing the task, summarize:
- How many ideas were created (saved to Vibeman at http://localhost:3000)
- Brief list of idea titles
- Any observations about the "pof" codebase

**Final Checklist:**
- [ ] I analyzed the "pof" codebase (READ ONLY)
- [ ] I did NOT create any new files in "pof"
- [ ] I saved ideas via curl to Vibeman's API at http://localhost:3000
- [ ] Each idea has effort, impact, and risk scores (1-10)
